# PHÆ¯Æ NG PHÃP THá»°C HIá»†N
## USSH SmartCampus Chatbot - Há»‡ Thá»‘ng Há»— Trá»£ Há»c Vá»¥ á»¨ng Dá»¥ng Kiáº¿n TrÃºc RAG

---

## 1. Tá»”NG QUAN PHÆ¯Æ NG PHÃP

### 1.1. Giá»›i thiá»‡u

Há»‡ thá»‘ng chatbot USSH SmartCampus Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn kiáº¿n trÃºc **RAG (Retrieval-Augmented Generation)**, káº¿t há»£p hai thÃ nh pháº§n chÃ­nh:
- **Retrieval System**: Há»‡ thá»‘ng truy xuáº¥t thÃ´ng tin tá»« cÆ¡ sá»Ÿ tri thá»©c
- **Generation System**: MÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n (LLM) Ä‘á»ƒ sinh cÃ¢u tráº£ lá»i

PhÆ°Æ¡ng phÃ¡p nÃ y cho phÃ©p chatbot tráº£ lá»i cÃ¡c cÃ¢u há»i dá»±a trÃªn nguá»“n tÃ i liá»‡u chÃ­nh thá»©c cá»§a trÆ°á»ng, Ä‘áº£m báº£o tÃ­nh chÃ­nh xÃ¡c vÃ  Ä‘Ã¡ng tin cáº­y.

### 1.2. LÃ½ do chá»n phÆ°Æ¡ng phÃ¡p RAG

**Æ¯u Ä‘iá»ƒm so vá»›i fine-tuning truyá»n thá»‘ng:**
- âœ“ KhÃ´ng cáº§n fine-tune model (tiáº¿t kiá»‡m thá»i gian, chi phÃ­)
- âœ“ Dá»… dÃ ng cáº­p nháº­t tri thá»©c (chá»‰ cáº§n cáº­p nháº­t vectorstore)
- âœ“ Minh báº¡ch: cÃ³ thá»ƒ trÃ­ch dáº«n nguá»“n
- âœ“ Giáº£m hallucination (bá»‹a Ä‘áº·t thÃ´ng tin)
- âœ“ KhÃ´ng giá»›i háº¡n bá»Ÿi context window cá»§a LLM

**So vá»›i rule-based chatbot:**
- âœ“ Linh hoáº¡t hÆ¡n, hiá»ƒu ngÃ´n ngá»¯ tá»± nhiÃªn
- âœ“ KhÃ´ng cáº§n Ä‘á»‹nh nghÄ©a trÆ°á»›c táº¥t cáº£ patterns
- âœ“ CÃ³ kháº£ nÄƒng reasoning vÃ  tá»•ng há»£p thÃ´ng tin

---

## 2. KIáº¾N TRÃšC Há»† THá»NG

### 2.1. Kiáº¿n trÃºc tá»•ng quÃ¡t

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      OFFLINE PHASE (Setup)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Document   â”‚  â†’   â”‚   Document   â”‚  â†’   â”‚    Text      â”‚ â”‚
â”‚  â”‚  Collection  â”‚      â”‚  Processing  â”‚      â”‚  Chunking    â”‚ â”‚
â”‚  â”‚ (PDF,DOCX,TXTâ”‚      â”‚   (OCR)      â”‚      â”‚ (Splitter)   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                       â”‚          â”‚
â”‚                                                       â–¼          â”‚
â”‚                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                                            â”‚    Embedding     â”‚ â”‚
â”‚                                            â”‚   (Vietnamese    â”‚ â”‚
â”‚                                            â”‚     SBERT)       â”‚ â”‚
â”‚                                            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                   â”‚              â”‚
â”‚                                                   â–¼              â”‚
â”‚                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                                            â”‚  Vector Database â”‚ â”‚
â”‚                                            â”‚   (ChromaDB)     â”‚ â”‚
â”‚                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ONLINE PHASE (Runtime)                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
â”‚  â”‚ User Query   â”‚                                               â”‚
â”‚  â”‚ (CÃ¢u há»i SV) â”‚                                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
â”‚         â”‚                                                        â”‚
â”‚         â–¼                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Query      â”‚  â†’   â”‚  Similarity  â”‚  â†’   â”‚  Retrieve    â”‚ â”‚
â”‚  â”‚  Embedding   â”‚      â”‚   Search     â”‚      â”‚   Top-K      â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚ (Cosine Sim) â”‚      â”‚  Documents   â”‚ â”‚
â”‚                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                      â”‚          â”‚
â”‚                                                      â–¼          â”‚
â”‚                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                                            â”‚    Context       â”‚ â”‚
â”‚                                            â”‚   Assembly       â”‚ â”‚
â”‚                                            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                   â”‚              â”‚
â”‚                                                   â–¼              â”‚
â”‚                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                                            â”‚  Prompt          â”‚ â”‚
â”‚                                            â”‚  Template        â”‚ â”‚
â”‚                                            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                   â”‚              â”‚
â”‚                                                   â–¼              â”‚
â”‚                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                                            â”‚      LLM         â”‚ â”‚
â”‚                                            â”‚   (Gemini 2.0)   â”‚ â”‚
â”‚                                            â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                   â”‚              â”‚
â”‚                                                   â–¼              â”‚
â”‚                                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚                                            â”‚   Response       â”‚ â”‚
â”‚                                            â”‚  + Citations     â”‚ â”‚
â”‚                                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2. CÃ¡c module chÃ­nh

#### **Module 1: Document Processing** (`src/document_processor.py`)
- Chá»©c nÄƒng: Xá»­ lÃ½ vÃ  chuáº©n bá»‹ dá»¯ liá»‡u
- Input: TÃ i liá»‡u thÃ´ (PDF, DOCX, TXT, MD)
- Output: CÃ¡c text chunks Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½

#### **Module 2: Embedding Management** (`src/embeddings.py`)
- Chá»©c nÄƒng: Quáº£n lÃ½ embedding models vÃ  vector database
- Input: Text chunks
- Output: Vector representations

#### **Module 3: Retrieval System** (`src/retriever.py`)
- Chá»©c nÄƒng: Truy xuáº¥t thÃ´ng tin liÃªn quan
- Input: User query
- Output: Top-K relevant documents

#### **Module 4: Chatbot Core** (`src/chatbot.py`)
- Chá»©c nÄƒng: Äiá»u phá»‘i toÃ n bá»™ pipeline RAG
- Input: User question
- Output: Generated answer vá»›i citations

#### **Module 5: User Interface**
- Web UI: `app.py` (Streamlit)
- CLI: `chatbot.py` (Command-line)

---

## 3. QUY TRÃŒNH THá»°C HIá»†N CHI TIáº¾T

### 3.1. GIAI ÄOáº N 1: Thu tháº­p vÃ  Chuáº©n bá»‹ Dá»¯ liá»‡u

#### 3.1.1. Thu tháº­p tÃ i liá»‡u

**Nguá»“n dá»¯ liá»‡u:**
- Quy cháº¿ Ä‘Ã o táº¡o
- Quy Ä‘á»‹nh vá» thi cá»­ vÃ  Ä‘Ã¡nh giÃ¡
- HÆ°á»›ng dáº«n Ä‘Äƒng kÃ½ há»c pháº§n
- ThÃ´ng tin vá» há»c phÃ­, há»c bá»•ng
- Quy Ä‘á»‹nh vá» cÃ´ng tÃ¡c sinh viÃªn
- TÃ i liá»‡u tá»« cÃ¡c phÃ²ng ban (CTSV, ÄT, KHTC)

**Äá»‹nh dáº¡ng há»— trá»£:**
- PDF (text-based vÃ  scan)
- Microsoft Word (DOCX)
- Plain text (TXT)
- Markdown (MD)

#### 3.1.2. Xá»­ lÃ½ OCR (náº¿u cáº§n)

**CÃ´ng cá»¥:** Tesseract OCR + pdf2image

**Quy trÃ¬nh:**
```python
1. PhÃ¡t hiá»‡n PDF scan:
   - Extract text tá»« page Ä‘áº§u tiÃªn
   - Náº¿u text < 50 kÃ½ tá»± â†’ coi lÃ  scan

2. Chuyá»ƒn Ä‘á»•i PDF sang images:
   - DPI: 300 (Ä‘áº£m báº£o cháº¥t lÆ°á»£ng)
   - Format: PNG

3. OCR tá»«ng trang:
   - Language: vie+eng (tiáº¿ng Viá»‡t + tiáº¿ng Anh)
   - Config: --psm 3 (automatic page segmentation)

4. LÆ°u káº¿t quáº£:
   - Format: TXT
   - Encoding: UTF-8
```

**Code implementation:**
```python
def ocr_pdf(pdf_path, output_path, lang='vie+eng'):
    images = convert_from_path(pdf_path, dpi=300)
    all_text = []
    
    for i, image in enumerate(images):
        text = pytesseract.image_to_string(image, lang=lang)
        all_text.append(f"--- Trang {i+1} ---\n{text}\n\n")
    
    with open(output_path, 'w', encoding='utf-8') as f:
        f.writelines(all_text)
```

#### 3.1.3. Document Loading

**Sá»­ dá»¥ng LangChain Document Loaders:**

| Äá»‹nh dáº¡ng | Loader | Äáº·c Ä‘iá»ƒm |
|-----------|--------|----------|
| PDF | `PyPDFLoader` | Preserve page numbers, metadata |
| DOCX | `Docx2txtLoader` | Extract text vÃ  formatting |
| TXT | `TextLoader` | Simple, UTF-8 encoding |
| MD | `UnstructuredMarkdownLoader` | Parse markdown structure |

**Metadata Ä‘Æ°á»£c preserve:**
- `source`: TÃªn file gá»‘c
- `page`: Sá»‘ trang (náº¿u cÃ³)
- `file_type`: Loáº¡i file (pdf, docx, txt, md)
- `file_path`: ÄÆ°á»ng dáº«n Ä‘áº§y Ä‘á»§

---

### 3.2. GIAI ÄOáº N 2: Text Chunking

#### 3.2.1. Chiáº¿n lÆ°á»£c Chunking

**PhÆ°Æ¡ng phÃ¡p:** RecursiveCharacterTextSplitter

**LÃ½ do chá»n:**
- ThÃ´ng minh: chia theo hierarchy (paragraph â†’ sentence â†’ word)
- Preserve context: giá»¯ nguyÃªn ngá»¯ cáº£nh quan trá»ng
- Flexible: tÃ¹y chá»‰nh separators

**Tham sá»‘:**
```yaml
chunk_size: 1000        # Sá»‘ kÃ½ tá»± má»—i chunk
chunk_overlap: 200      # Overlap giá»¯a cÃ¡c chunks
separators:
  - "\n\n"              # Paragraph (Æ°u tiÃªn cao nháº¥t)
  - "\n"                # Line break
  - " "                 # Space
  - ""                  # Character-level (cuá»‘i cÃ¹ng)
```

**Giáº£i thÃ­ch tham sá»‘:**

**1. Chunk Size = 1000 kÃ½ tá»±**
- LÃ½ do: 
  - Äá»§ lá»›n Ä‘á»ƒ chá»©a thÃ´ng tin Ä‘áº§y Ä‘á»§ (thÆ°á»ng 1-2 Ä‘oáº¡n vÄƒn)
  - Äá»§ nhá» Ä‘á»ƒ embedding chÃ­nh xÃ¡c
  - TÆ°Æ¡ng Ä‘Æ°Æ¡ng ~250 tokens (1 token â‰ˆ 4 kÃ½ tá»± tiáº¿ng Viá»‡t)
- Trade-off:
  - QuÃ¡ lá»›n: Loss semantic meaning, slow retrieval
  - QuÃ¡ nhá»: Thiáº¿u context, nhiá»u chunks hÆ¡n

**2. Chunk Overlap = 200 kÃ½ tá»±**
- LÃ½ do:
  - TrÃ¡nh cáº¯t ngang thÃ´ng tin quan trá»ng
  - Äáº£m báº£o continuity giá»¯a cÃ¡c chunks
  - 20% overlap lÃ  tá»· lá»‡ tá»‘i Æ°u (theo best practices)
- VÃ­ dá»¥:
  ```
  Chunk 1: [0-1000] kÃ½ tá»±
  Chunk 2: [800-1800] kÃ½ tá»± (overlap 200 kÃ½ tá»± vá»›i chunk 1)
  ```

**3. Separators Hierarchy**
```python
separators = ["\n\n", "\n", " ", ""]
```
- Má»©c 1: `\n\n` - Chia theo Ä‘oáº¡n vÄƒn (preferred)
- Má»©c 2: `\n` - Chia theo dÃ²ng náº¿u khÃ´ng tÃ¬m tháº¥y paragraph
- Má»©c 3: ` ` - Chia theo tá»« náº¿u khÃ´ng tÃ¬m tháº¥y line break
- Má»©c 4: `""` - Chia theo kÃ½ tá»± (worst case)

#### 3.2.2. Implementation

```python
from langchain.text_splitter import RecursiveCharacterTextSplitter

text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    separators=["\n\n", "\n", " ", ""],
    length_function=len,
)

chunks = text_splitter.split_documents(documents)
```

**Káº¿t quáº£ vÃ­ dá»¥:**
```
Input: 50 documents (300 pages)
Output: ~800 chunks
Average chunk size: 850 kÃ½ tá»±
```

---

### 3.3. GIAI ÄOáº N 3: Embedding vÃ  Vector Database

#### 3.3.1. Embedding Model

**Model Ä‘Æ°á»£c chá»n:** `keepitreal/vietnamese-sbert`

**Äáº·c Ä‘iá»ƒm:**
- Kiáº¿n trÃºc: Sentence-BERT (Bi-encoder)
- Base model: PhoBERT (Vietnamese BERT)
- Output dimension: 768
- Training data: Vietnamese sentence pairs
- Performance: Cosine similarity correlation > 0.85

**LÃ½ do chá»n:**
1. **Tá»‘i Æ°u cho tiáº¿ng Viá»‡t**: Train trÃªn corpus tiáº¿ng Viá»‡t
2. **Semantic understanding**: Hiá»ƒu nghÄ©a cÃ¢u, khÃ´ng chá»‰ tá»« khÃ³a
3. **Free & Local**: Cháº¡y local, khÃ´ng phÃ­ API
4. **Fast inference**: ~50ms/embedding trÃªn CPU

**So sÃ¡nh vá»›i cÃ¡c alternatives:**

| Model | Pros | Cons | Use case |
|-------|------|------|----------|
| `vietnamese-sbert` | Tá»‘t nháº¥t cho tiáº¿ng Viá»‡t | Cáº§n download model (~500MB) | **ÄÆ°á»£c chá»n** |
| `multilingual-e5-base` | Multilingual, SOTA | KÃ©m hÆ¡n cho tiáº¿ng Viá»‡t | Backup option |
| `text-embedding-ada-002` | Cháº¥t lÆ°á»£ng cao | Tráº£ phÃ­, phá»¥ thuá»™c API | Production vá»›i budget |

#### 3.3.2. Embedding Process

```python
from langchain_community.embeddings import HuggingFaceEmbeddings

embeddings = HuggingFaceEmbeddings(
    model_name="keepitreal/vietnamese-sbert",
    model_kwargs={'device': 'cpu'},        # Hoáº·c 'cuda' náº¿u cÃ³ GPU
    encode_kwargs={'normalize_embeddings': True}  # L2 normalization
)

# Generate embeddings
vector = embeddings.embed_query("Äiá»u kiá»‡n tá»‘t nghiá»‡p lÃ  gÃ¬?")
# Output: array of 768 float numbers
```

**Normalization:**
- Táº¥t cáº£ vectors Ä‘Æ°á»£c normalize vá» unit length
- LÃ½ do: Cosine similarity = dot product khi normalized
- TÄƒng tá»‘c Ä‘á»™ tÃ­nh toÃ¡n

#### 3.3.3. Vector Database - ChromaDB

**Kiáº¿n trÃºc ChromaDB:**
```
ChromaDB
â”œâ”€â”€ Collections (student_support_docs)
â”‚   â”œâ”€â”€ Documents (text chunks)
â”‚   â”œâ”€â”€ Embeddings (768-dim vectors)
â”‚   â”œâ”€â”€ Metadata (source, page, etc.)
â”‚   â””â”€â”€ IDs (unique identifiers)
â”œâ”€â”€ Indices (HNSW - Hierarchical Navigable Small World)
â””â”€â”€ Storage (SQLite + Binary files)
```

**TÃ­nh nÄƒng chÃ­nh:**
- **Persistent storage**: Dá»¯ liá»‡u Ä‘Æ°á»£c lÆ°u trÃªn disk
- **Fast search**: HNSW algorithm (logarithmic complexity)
- **Metadata filtering**: Lá»c theo source, page, etc.
- **Batch operations**: ThÃªm nhiá»u documents cÃ¹ng lÃºc

**Implementation:**
```python
from langchain.vectorstores import Chroma

vectorstore = Chroma.from_documents(
    documents=chunks,
    embedding=embeddings,
    persist_directory="./data/vectorstore",
    collection_name="student_support_docs"
)

vectorstore.persist()  # Save to disk
```

**Storage structure:**
```
data/vectorstore/
â”œâ”€â”€ chroma.sqlite3              # Metadata database
â””â”€â”€ 38015ad0-6fcf.../          # Collection directory
    â”œâ”€â”€ data_level0.bin        # HNSW index level 0
    â”œâ”€â”€ header.bin             # Index metadata
    â”œâ”€â”€ length.bin             # Vector lengths
    â””â”€â”€ link_lists.bin         # HNSW graph structure
```

**Thá»‘ng kÃª vÃ­ dá»¥:**
- Number of vectors: 800
- Vector dimension: 768
- Storage size: ~150 MB
- Index build time: ~2 minutes
- Query time: ~50ms

---

### 3.4. GIAI ÄOáº N 4: Retrieval System

#### 3.4.1. Similarity Search Algorithm

**Thuáº­t toÃ¡n:** HNSW (Hierarchical Navigable Small World)

**NguyÃªn lÃ½:**
```
1. Build phase (offline):
   - Táº¡o multi-layer graph
   - Má»—i node lÃ  má»™t vector
   - Edges káº¿t ná»‘i cÃ¡c vectors gáº§n nhau

2. Search phase (online):
   - Start tá»« layer cao nháº¥t
   - Greedy search Ä‘áº¿n local minimum
   - Move down layers
   - Refine search á»Ÿ layer 0
```

**Complexity:**
- Build: O(N log N)
- Search: O(log N)
- Memory: O(N)

**Distance metric:** Cosine Similarity

```
cosine_similarity(A, B) = (A Â· B) / (||A|| Ã— ||B||)

Vá»›i normalized vectors: cosine_similarity(A, B) = A Â· B
```

**Range:** [-1, 1]
- 1: HoÃ n toÃ n giá»‘ng nhau
- 0: KhÃ´ng liÃªn quan
- -1: HoÃ n toÃ n Ä‘á»‘i láº­p (hiáº¿m khi xáº£y ra)

#### 3.4.2. Retrieval Process

```python
def retrieve(query: str, top_k: int = 5):
    """
    BÆ°á»›c 1: Embed query
    """
    query_vector = embeddings.embed_query(query)
    
    """
    BÆ°á»›c 2: Similarity search
    """
    results = vectorstore.similarity_search_with_score(
        query,
        k=top_k
    )
    # Returns: [(doc1, score1), (doc2, score2), ...]
    
    """
    BÆ°á»›c 3: Score filtering
    """
    threshold = 0.5
    filtered = [(doc, score) for doc, score in results 
                if score >= threshold]
    
    """
    BÆ°á»›c 4: Return documents
    """
    return [doc for doc, _ in filtered]
```

**Tham sá»‘:**
- `top_k = 5`: Láº¥y 5 chunks liÃªn quan nháº¥t
  - LÃ½ do: Balance giá»¯a context vÃ  noise
  - Trade-off: Nhiá»u hÆ¡n â†’ nhiá»u context nhÆ°ng cháº­m vÃ  nhiá»…u
  
- `score_threshold = 0.5`: Lá»c káº¿t quáº£ cÃ³ similarity < 0.5
  - LÃ½ do: Äáº£m báº£o cháº¥t lÆ°á»£ng káº¿t quáº£
  - Trong thá»±c táº¿: Scores thÆ°á»ng 0.6-0.9 cho queries liÃªn quan

#### 3.4.3. Context Assembly

**Má»¥c Ä‘Ã­ch:** Káº¿t há»£p cÃ¡c chunks thÃ nh context cho LLM

```python
def get_context_string(documents):
    context_parts = []
    
    for i, doc in enumerate(documents, 1):
        source = doc.metadata.get('source', 'Unknown')
        page = doc.metadata.get('page', '')
        
        context_parts.append(
            f"[TÃ i liá»‡u {i}] Nguá»“n: {source} (Trang {page})\n"
            f"{doc.page_content}\n"
        )
    
    return "\n---\n".join(context_parts)
```

**Káº¿t quáº£ vÃ­ dá»¥:**
```
[TÃ i liá»‡u 1] Nguá»“n: quy_che_dao_tao.pdf (Trang 15)
Äiá»u 25. Äiá»u kiá»‡n xÃ©t tá»‘t nghiá»‡p
Sinh viÃªn Ä‘Æ°á»£c xÃ©t tá»‘t nghiá»‡p khi Ä‘Ã¡p á»©ng Ä‘á»§ cÃ¡c Ä‘iá»u kiá»‡n sau:
1. TÃ­ch lÅ©y Ä‘á»§ sá»‘ tÃ­n chá»‰ theo chÆ°Æ¡ng trÃ¬nh...
2. Äiá»ƒm trung bÃ¬nh tÃ­ch lÅ©y Ä‘áº¡t tá»« 2.0 trá»Ÿ lÃªn...

---

[TÃ i liá»‡u 2] Nguá»“n: huong_dan_tot_nghiep.pdf (Trang 3)
Quy trÃ¬nh ná»™p há»“ sÆ¡ xÃ©t tá»‘t nghiá»‡p:
- BÆ°á»›c 1: Kiá»ƒm tra Ä‘iá»u kiá»‡n...
- BÆ°á»›c 2: Ná»™p Ä‘Æ¡n Ä‘Äƒng kÃ½...
```

---

### 3.5. GIAI ÄOáº N 5: LLM Generation

#### 3.5.1. LLM Selection

**Model Ä‘Æ°á»£c chá»n:** Google Gemini 2.0 Flash

**ThÃ´ng sá»‘ ká»¹ thuáº­t:**
- Model family: Gemini 2.0
- Variant: Flash (optimized for speed)
- Context window: 1M tokens
- Output max: 8K tokens
- Languages: 100+ including Vietnamese
- Pricing: Free tier available

**So sÃ¡nh vá»›i alternatives:**

| Model | Speed | Quality | Cost | Vietnamese | Chá»n |
|-------|-------|---------|------|------------|------|
| Gemini 2.0 Flash | â­â­â­â­â­ | â­â­â­â­ | Free | â­â­â­â­â­ | âœ… |
| GPT-4 | â­â­â­ | â­â­â­â­â­ | $$$$ | â­â­â­â­ | âŒ |
| GPT-3.5 Turbo | â­â­â­â­ | â­â­â­ | $$ | â­â­â­â­ | âŒ |
| Claude 3 | â­â­â­â­ | â­â­â­â­â­ | $$$ | â­â­â­â­ | âŒ |

**LÃ½ do chá»n Gemini 2.0 Flash:**
1. **Free tier**: PhÃ¹ há»£p cho prototype vÃ  academic project
2. **Excellent Vietnamese**: ÄÆ°á»£c train tá»‘t trÃªn tiáº¿ng Viá»‡t
3. **Fast**: Optimized for low latency
4. **Large context**: 1M tokens (khÃ´ng giá»›i háº¡n bá»Ÿi context)
5. **Multi-modal**: Sáºµn sÃ ng cho future features (image, audio)

#### 3.5.2. Prompt Engineering

**Prompt Template:**

```python
template = """
{system_prompt}

CONTEXT (ThÃ´ng tin tá»« tÃ i liá»‡u cá»§a trÆ°á»ng):
{context}

QUESTION (CÃ¢u há»i cá»§a sinh viÃªn):
{question}

ANSWER (CÃ¢u tráº£ lá»i cá»§a báº¡n):
"""
```

**System Prompt:**
```
Báº¡n lÃ  trá»£ lÃ½ áº£o há»— trá»£ sinh viÃªn cá»§a TrÆ°á»ng Äáº¡i há»c Khoa há»c XÃ£ há»™i 
vÃ  NhÃ¢n vÄƒn - ÄHQG-HCM (USSH).

NHIá»†M Vá»¤:
- Tráº£ lá»i cÃ¡c cÃ¢u há»i cá»§a sinh viÃªn dá»±a trÃªn thÃ´ng tin tá»« cÃ¡c vÄƒn báº£n, 
  quy Ä‘á»‹nh cá»§a trÆ°á»ng Ä‘Æ°á»£c cung cáº¥p trong CONTEXT
- LuÃ´n trÃ­ch dáº«n nguá»“n thÃ´ng tin khi tráº£ lá»i
- Náº¿u khÃ´ng cÃ³ thÃ´ng tin trong CONTEXT, hÃ£y nÃ³i rÃµ vÃ  hÆ°á»›ng dáº«n 
  sinh viÃªn liÃªn há»‡ phÃ²ng ban liÃªn quan

PHONG CÃCH TRáº¢ Lá»œI:
- ChÃ­nh xÃ¡c: Chá»‰ dá»±a trÃªn thÃ´ng tin Ä‘Æ°á»£c cung cáº¥p
- RÃµ rÃ ng: CÃ¢u tráº£ lá»i dá»… hiá»ƒu, cÃ³ cáº¥u trÃºc
- ThÃ¢n thiá»‡n: Giá»ng Ä‘iá»‡u lá»‹ch sá»±, gáº§n gÅ©i
- Ngáº¯n gá»n: Äi tháº³ng vÃ o váº¥n Ä‘á», trÃ¡nh lan man

QUY Táº®C QUAN TRá»ŒNG:
1. KHÃ”NG bá»‹a Ä‘áº·t thÃ´ng tin khÃ´ng cÃ³ trong CONTEXT
2. KHÃ”NG Ä‘Æ°a ra Ã½ kiáº¿n cÃ¡ nhÃ¢n
3. KHÃ”NG tráº£ lá»i cÃ¡c cÃ¢u há»i khÃ´ng liÃªn quan Ä‘áº¿n há»c vá»¥
4. LuÃ´n kiá»ƒm tra láº¡i thÃ´ng tin trÆ°á»›c khi tráº£ lá»i
```

**Ká»¹ thuáº­t Prompt Engineering Ä‘Æ°á»£c Ã¡p dá»¥ng:**

1. **Role Definition**: Äá»‹nh nghÄ©a rÃµ vai trÃ²
2. **Task Description**: MÃ´ táº£ nhiá»‡m vá»¥ cá»¥ thá»ƒ
3. **Style Guidelines**: HÆ°á»›ng dáº«n phong cÃ¡ch
4. **Constraints**: Äáº·t ra cÃ¡c rÃ ng buá»™c
5. **Few-shot Examples** (optional): CÃ³ thá»ƒ thÃªm examples

#### 3.5.3. Generation Process

```python
def generate_answer(question: str, context: str):
    """
    BÆ°á»›c 1: Format prompt
    """
    prompt = template.format(
        system_prompt=system_prompt,
        context=context,
        question=question
    )
    
    """
    BÆ°á»›c 2: Call LLM API
    """
    response = model.generate_content(
        prompt,
        generation_config={
            'temperature': 0.7,      # Creativity level
            'top_p': 0.9,           # Nucleus sampling
            'max_output_tokens': 1500,
            'candidate_count': 1
        }
    )
    
    """
    BÆ°á»›c 3: Extract and clean response
    """
    answer = response.text
    
    # Remove HTML tags if any
    answer = answer.replace('</div>', '').strip()
    
    # Remove file references (e.g., "(document.txt)")
    if answer.endswith(')'):
        last_paren = answer.rfind('(')
        if last_paren > 0 and '.txt' in answer[last_paren:]:
            answer = answer[:last_paren].strip()
    
    return answer
```

**Generation Config Parameters:**

| Parameter | Value | Ã nghÄ©a | TÃ¡c Ä‘á»™ng |
|-----------|-------|---------|----------|
| `temperature` | 0.7 | Äá»™ "sÃ¡ng táº¡o" | 0=deterministic, 1=random |
| `top_p` | 0.9 | Nucleus sampling | Chá»n tá»« top 90% probable tokens |
| `max_tokens` | 1500 | Max Ä‘á»™ dÃ i output | ~375 tá»« tiáº¿ng Viá»‡t |
| `candidate_count` | 1 | Sá»‘ responses | Chá»‰ láº¥y 1 cÃ¢u tráº£ lá»i tá»‘t nháº¥t |

**Temperature tuning:**
- `0.0-0.3`: Ráº¥t deterministic, phÃ¹ há»£p factual QA
- `0.4-0.7`: **Balanced** (Ä‘Æ°á»£c chá»n)
- `0.8-1.0`: Creative, cÃ³ thá»ƒ hallucinate

---

### 3.6. GIAI ÄOáº N 6: Response Post-processing

#### 3.6.1. Answer Validation

```python
def validate_answer(answer: str) -> bool:
    """
    Kiá»ƒm tra xem cÃ¢u tráº£ lá»i cÃ³ pháº£i lÃ  "khÃ´ng biáº¿t" khÃ´ng
    """
    no_answer_keywords = [
        'xin lá»—i', 'khÃ´ng tÃ¬m tháº¥y', 'khÃ´ng cÃ³ thÃ´ng tin',
        'khÃ´ng rÃµ', 'khÃ´ng biáº¿t', 'chÆ°a cÃ³ thÃ´ng tin',
        'khÃ´ng tÃ¬m Ä‘Æ°á»£c', 'khÃ´ng cÃ³ dá»¯ liá»‡u', 'khÃ´ng Ä‘á» cáº­p'
    ]
    
    is_no_answer = any(
        keyword in answer.lower() 
        for keyword in no_answer_keywords
    )
    
    return not is_no_answer
```

#### 3.6.2. Source Citation

```python
def get_source_references(documents):
    """
    Extract unique sources tá»« retrieved documents
    """
    sources = []
    seen = set()
    
    for doc in documents:
        source_id = (
            doc.metadata.get('source', 'Unknown'),
            doc.metadata.get('page', '')
        )
        
        if source_id not in seen:
            sources.append({
                'source': doc.metadata.get('source'),
                'page': doc.metadata.get('page'),
                'file_type': doc.metadata.get('file_type')
            })
            seen.add(source_id)
    
    return sources
```

#### 3.6.3. Final Response Format

```json
{
    "question": "Äiá»u kiá»‡n tá»‘t nghiá»‡p USSH lÃ  gÃ¬?",
    "answer": "Theo quy Ä‘á»‹nh cá»§a trÆ°á»ng, sinh viÃªn Ä‘Æ°á»£c xÃ©t tá»‘t nghiá»‡p khi Ä‘Ã¡p á»©ng Ä‘á»§ cÃ¡c Ä‘iá»u kiá»‡n sau:\n1. HoÃ n thÃ nh Ä‘á»§ sá»‘ tÃ­n chá»‰ theo chÆ°Æ¡ng trÃ¬nh Ä‘Ã o táº¡o\n2. Äiá»ƒm trung bÃ¬nh tÃ­ch lÅ©y Ä‘áº¡t tá»« 2.0 trá»Ÿ lÃªn\n3. KhÃ´ng vi pháº¡m ká»· luáº­t...",
    "sources": [
        {
            "source": "quy_che_dao_tao.pdf",
            "page": "15",
            "file_type": "pdf"
        },
        {
            "source": "huong_dan_tot_nghiep.pdf",
            "page": "3",
            "file_type": "pdf"
        }
    ],
    "num_sources": 5,
    "confidence": "high"
}
```

---

## 4. GIAO DIá»†N NGÆ¯á»œI DÃ™NG

### 4.1. Web Interface (Streamlit)

**Kiáº¿n trÃºc:**
```python
app.py (Streamlit App)
â”œâ”€â”€ Configuration (Page config, CSS)
â”œâ”€â”€ Session State Management
â”œâ”€â”€ Sidebar (Settings, Examples)
â”œâ”€â”€ Main Chat Interface
â”‚   â”œâ”€â”€ Chat History Display
â”‚   â”œâ”€â”€ Message Input
â”‚   â””â”€â”€ Response Rendering
â””â”€â”€ Footer
```

**TÃ­nh nÄƒng chÃ­nh:**

1. **Chat History**: LÆ°u vÃ  hiá»ƒn thá»‹ lá»‹ch sá»­ chat
   ```python
   if "messages" not in st.session_state:
       st.session_state.messages = []
   ```

2. **Source Display**: Hiá»ƒn thá»‹ nguá»“n tham kháº£o Ä‘áº¹p máº¯t
   ```python
   st.markdown(f"""
   <div class='source-box'>
       <strong>ğŸ“š Nguá»“n:</strong><br>
       {source['source']} (Trang {source['page']})
   </div>
   """, unsafe_allow_html=True)
   ```

3. **Dynamic Settings**: Äiá»u chá»‰nh top_k, include_sources
   ```python
   top_k = st.slider("Äá»™ sÃ¢u tÃ¬m kiáº¿m", 1, 10, 5)
   include_sources = st.checkbox("Hiá»ƒn thá»‹ nguá»“n", True)
   ```

4. **Example Questions**: Gá»£i Ã½ cÃ¢u há»i thÆ°á»ng gáº·p
   ```python
   example_questions = [
       "Äiá»u kiá»‡n tá»‘t nghiá»‡p USSH?",
       "Quy Ä‘á»‹nh vá» Ä‘iá»ƒm danh?",
       ...
   ]
   ```

**UI/UX Design Principles:**
- **USSH Branding**: Sá»­ dá»¥ng mÃ u xanh chá»§ Ä‘áº¡o cá»§a trÆ°á»ng
- **Responsive**: Tá»± Ä‘á»™ng adapt vá»›i mobile/desktop
- **Accessibility**: Dá»… sá»­ dá»¥ng cho má»i Ä‘á»‘i tÆ°á»£ng
- **Performance**: Cache chatbot instance, lazy loading

### 4.2. CLI Interface

**ÄÆ¡n giáº£n hÆ¡n, phÃ¹ há»£p cho:**
- Testing vÃ  debugging
- Server deployment (khÃ´ng cáº§n GUI)
- Automation scripts

```python
while True:
    question = input("\nâ“ CÃ¢u há»i: ")
    if question.lower() in ['exit', 'quit']:
        break
    
    response = chatbot.ask(question)
    print(chatbot.format_response(response))
```

---

## 5. Tá»I á»°U HÃ“A VÃ€ ÄÃNH GIÃ

### 5.1. Metrics ÄÃ¡nh GiÃ¡

#### 5.1.1. Retrieval Metrics

**1. Precision@K**
```
Precision@K = (Sá»‘ documents liÃªn quan trong top-K) / K
```

**2. Recall@K**
```
Recall@K = (Sá»‘ documents liÃªn quan Ä‘Æ°á»£c retrieve) / (Tá»•ng sá»‘ documents liÃªn quan)
```

**3. Mean Reciprocal Rank (MRR)**
```
MRR = 1/N Ã— Î£(1/rank_i)
```
Vá»›i rank_i lÃ  vá»‹ trÃ­ cá»§a document liÃªn quan Ä‘áº§u tiÃªn

#### 5.1.2. Generation Metrics

**1. BLEU Score** (náº¿u cÃ³ ground truth)
- Äo Ä‘á»™ giá»‘ng vá»›i cÃ¢u tráº£ lá»i chuáº©n

**2. Human Evaluation**
- Accuracy: ChÃ­nh xÃ¡c (1-5)
- Relevance: LiÃªn quan (1-5)
- Completeness: Äáº§y Ä‘á»§ (1-5)
- Clarity: RÃµ rÃ ng (1-5)

**3. Source Attribution Rate**
```
Attribution Rate = (Sá»‘ cÃ¢u tráº£ lá»i cÃ³ source) / (Tá»•ng sá»‘ cÃ¢u tráº£ lá»i)
```

### 5.2. Optimization Techniques

#### 5.2.1. Retrieval Optimization

**1. Chunk Size Tuning**
```python
# Test different sizes
chunk_sizes = [500, 800, 1000, 1200, 1500]
for size in chunk_sizes:
    evaluate_retrieval(chunk_size=size)
```

**2. Top-K Tuning**
```python
# Find optimal K
ks = [3, 5, 7, 10]
for k in ks:
    evaluate_quality(top_k=k)
```

**3. Score Threshold Tuning**
```python
# Balance precision and recall
thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]
for t in thresholds:
    evaluate_retrieval(threshold=t)
```

#### 5.2.2. Generation Optimization

**1. Temperature Tuning**
```python
temperatures = [0.3, 0.5, 0.7, 0.9]
for temp in temperatures:
    responses = generate_batch(temperature=temp)
    evaluate_quality(responses)
```

**2. Prompt Optimization**
- A/B testing different prompts
- Add few-shot examples
- Refine instructions

**3. Context Length Optimization**
```python
# Test vá»›i different max context length
max_lengths = [2000, 3000, 4000, 5000]
```

### 5.3. Caching vÃ  Performance

#### 5.3.1. Embedding Cache
```python
@lru_cache(maxsize=1000)
def cached_embed_query(query: str):
    return embeddings.embed_query(query)
```

#### 5.3.2. Streamlit Cache
```python
@st.cache_resource
def load_chatbot():
    return StudentSupportChatbot()
```

#### 5.3.3. Batch Processing
```python
# Process documents in batches
batch_size = 100
for i in range(0, len(documents), batch_size):
    batch = documents[i:i+batch_size]
    vectorstore.add_documents(batch)
```

---

## 6. LOGGING VÃ€ MONITORING

### 6.1. Logging System

**Cáº¥u trÃºc logs:**
```
logs/chatbot.log
â”œâ”€â”€ INFO: System initialization
â”œâ”€â”€ INFO: User query received
â”œâ”€â”€ DEBUG: Retrieved documents (scores)
â”œâ”€â”€ INFO: LLM generation time
â”œâ”€â”€ INFO: Response returned
â””â”€â”€ ERROR: Error details (if any)
```

**Log format:**
```
2024-01-15 10:30:45 - chatbot - INFO - â“ Question: Äiá»u kiá»‡n tá»‘t nghiá»‡p?
2024-01-15 10:30:45 - retriever - DEBUG - Retrieved 5 docs (scores: 0.87, 0.82, ...)
2024-01-15 10:30:47 - chatbot - INFO - âœ… Answer generated (time: 2.1s)
```

### 6.2. Monitoring Metrics

**Tracking:**
- Number of queries per day
- Average response time
- Top queries
- Error rate
- Source attribution rate

**Dashboard (future):**
```python
metrics = {
    'total_queries': count_queries(),
    'avg_response_time': calculate_avg_time(),
    'top_queries': get_top_queries(n=10),
    'error_rate': calculate_error_rate(),
    'satisfaction_score': get_user_ratings()
}
```

---

## 7. Káº¾T LUáº¬N PHÆ¯Æ NG PHÃP

### 7.1. Æ¯u Ä‘iá»ƒm cá»§a PhÆ°Æ¡ng phÃ¡p

1. **ChÃ­nh xÃ¡c cao**: Dá»±a trÃªn tÃ i liá»‡u chÃ­nh thá»©c
2. **Minh báº¡ch**: TrÃ­ch dáº«n nguá»“n rÃµ rÃ ng
3. **Dá»… cáº­p nháº­t**: Chá»‰ cáº§n thÃªm documents má»›i
4. **Linh hoáº¡t**: Há»— trá»£ nhiá»u LLM vÃ  embedding models
5. **Scalable**: CÃ³ thá»ƒ má»Ÿ rá»™ng cho nhiá»u trÆ°á»ng
6. **Cost-effective**: Sá»­ dá»¥ng free tiers

### 7.2. Háº¡n cháº¿ vÃ  HÆ°á»›ng Giáº£i quyáº¿t

| Háº¡n cháº¿ | TÃ¡c Ä‘á»™ng | Giáº£i phÃ¡p |
|---------|----------|-----------|
| Phá»¥ thuá»™c cháº¥t lÆ°á»£ng documents | Náº¿u docs kÃ©m â†’ káº¿t quáº£ kÃ©m | Cáº£i thiá»‡n OCR, preprocessing |
| KhÃ´ng xá»­ lÃ½ multi-turn conversation | Thiáº¿u context lá»‹ch sá»­ | Implement conversation memory |
| CÃ³ thá»ƒ miss information | Náº¿u chunking khÃ´ng tá»‘t | Optimize chunk size, overlap |
| Latency (~2-3s) | User experience | Caching, async processing |

### 7.3. HÆ°á»›ng PhÃ¡t triá»ƒn

**Ngáº¯n háº¡n (1-3 thÃ¡ng):**
- Implement re-ranking
- Add conversation history
- Improve OCR quality

**Trung háº¡n (3-6 thÃ¡ng):**
- Fine-tune embedding model
- Add analytics dashboard
- Multi-language support

**DÃ i háº¡n (6-12 thÃ¡ng):**
- Voice interface
- Mobile app
- Integration vá»›i há»‡ thá»‘ng trÆ°á»ng

---

## PHá»¤ Lá»¤C

### A. Cáº¥u hÃ¬nh Äáº§y Ä‘á»§

```yaml
# config/config.yaml
document_processing:
  supported_formats: [pdf, docx, txt, md]
  chunk_size: 1000
  chunk_overlap: 200
  separators: ["\n\n", "\n", " ", ""]

embedding:
  provider: "sentence-transformers"
  model_name: "keepitreal/vietnamese-sbert"
  batch_size: 32

vectorstore:
  type: "chromadb"
  persist_directory: "./data/vectorstore"
  collection_name: "student_support_docs"
  distance_metric: "cosine"

llm:
  provider: "gemini"
  model_name: "models/gemini-2.0-flash"
  temperature: 0.7
  max_tokens: 1500
  top_p: 0.9

retrieval:
  top_k: 5
  score_threshold: 0.5
  rerank: false

response:
  language: "vi"
  include_sources: true
  max_source_length: 200

logging:
  level: "INFO"
  file: "./logs/chatbot.log"
```

### B. Dependencies

```
langchain>=0.1.0
langchain-community>=0.1.0
langchain-openai>=0.0.5
chromadb>=0.4.0
sentence-transformers>=2.2.0
streamlit>=1.29.0
python-dotenv>=1.0.0
pyyaml>=6.0
pypdf2>=3.0.0
pdfplumber>=0.10.0
python-docx>=1.0.0
pytesseract>=0.3.10
pdf2image>=1.16.0
pillow>=10.0.0
tqdm>=4.65.0
google-generativeai>=0.3.0
```

### C. TÃ i liá»‡u Tham kháº£o

1. Lewis, P., et al. (2020). "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks". NeurIPS.
2. Reimers, N., & Gurevych, I. (2019). "Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks". EMNLP.
3. Malkov, Y., & Yashunin, D. (2018). "Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs". IEEE.
4. Google DeepMind (2024). "Gemini 2.0: Technical Report".
5. LangChain Documentation: https://python.langchain.com/

---

**TÃ i liá»‡u nÃ y mÃ´ táº£ chi tiáº¿t phÆ°Æ¡ng phÃ¡p thá»±c hiá»‡n há»‡ thá»‘ng USSH SmartCampus Chatbot.**

*PhiÃªn báº£n: 1.0*  
*NgÃ y cáº­p nháº­t: 2024*


